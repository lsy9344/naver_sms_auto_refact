# Story 5.4: Implement Monitoring Infrastructure

**Status:** Updated (v2.0 - Validation-Only Strategy)

**⚠️ Strategy Change:** Story scope updated to reflect validation-only approach. Legacy Lambda non-operational; no parallel deployment. Monitoring infrastructure now supports offline validation and production readiness instead of real-time comparison.

---

## Quick Project Assessment

**Current System Context**
- [x] Production monitoring infrastructure must be operational before cutover to detect issues immediately after new Lambda goes live (`docs/epics/epic-5-deployment.md:263-267`).
- [x] CloudWatch dashboard, alarms, and Telegram notifications are required for Day 0 go/no-go decisions to ensure observability is ready (`docs/epics/epic-5-deployment.md:263-267`, `docs/epics/epic-5-deployment.md:297-310`).
- [x] Offline validation campaign (Story 5.5) benefits from monitoring infrastructure being ready to capture validation run metrics and errors (`docs/brownfield-architecture.md:1683-1710`).
- [x] Rollback procedures require fast detection of production issues via CloudWatch alarms to minimize customer impact (`docs/prd.md:434-438`, `docs/epics/epic-5-deployment.md:181-207`).

**Change Scope**
- [x] Instrument new Lambda to emit structured logs for Lambda invocations, errors, SMS counts, DynamoDB operations, and Telegram notifications into CloudWatch Logs (`docs/epics/epic-5-deployment.md:162-177`).
- [x] Publish CloudWatch custom metrics for operational visibility: SMS sent by type/store, SENS API call counts, error rates, execution duration (`docs/epics/epic-5-deployment.md:162-177`, `docs/epics/epic-5-deployment.md:321-349`).
- [x] Configure CloudWatch alarms for Lambda errors, duration, throttling, and DynamoDB throttling with Telegram notification targets (`docs/epics/epic-5-deployment.md:321-349`).
- [x] Build CloudWatch dashboard showing Lambda health, DynamoDB capacity, SENS metrics, and SMS delivery statistics to support operations and validation campaigns (`docs/epics/epic-5-deployment.md:344-349`).
- [x] Update operational runbooks and CloudWatch query catalog so teams can investigate issues and validate alarm responses before production cutover (`docs/ops/runbook.md:1`, `docs/ops/cloudwatch-queries.md:1`).

---

## Story

**As a** production reliability engineer,
**I want** to implement comprehensive CloudWatch monitoring infrastructure for the new Lambda,
**so that** we can detect and respond to production issues immediately after cutover and validate system health during offline validation campaigns.

---

## Story Context

- Comparison monitoring is a prerequisite for enabling both Lambdas at the Day 0 go/no-go checkpoint, so instrumentation must be production-ready before the parallel rollout begins (`docs/epics/epic-5-deployment.md:260-265`).
- The monitoring & alerting plan defines the exact metrics, thresholds, and notification channels that the dashboard and alarms must use (`docs/epics/epic-5-deployment.md:282-304`).
- Runbook and CloudWatch Logs Insights playbooks rely on structured log fields, so comparison output must align with existing logging conventions for smooth incident response (`docs/ops/runbook.md:5-153`, `docs/ops/cloudwatch-queries.md:15-112`).
- Functional parity success criteria requires evidence of 100% match across a 1-week validation window, meaning the monitoring solution has to store historical metrics for auditing (`docs/prd.md:280-288`, `docs/epics/epic-5-deployment.md:231-235`).
- Legacy comparison utilities were previously verified but are not currently deployed; this rollout must respect manual approval gates before any SMS reaches customers and only interact with live SENS endpoints once explicitly authorized by the owner.

---

## Acceptance Criteria

**Functional Requirements**
1. Each invocation emits a structured comparison log capturing SMS counts by type, DynamoDB writes/updates, Telegram notifications, and any detected deltas between old and new Lambda outputs, queryable through CloudWatch Logs Insights (`docs/epics/epic-5-deployment.md:132-138`, `docs/ops/cloudwatch-queries.md:55-112`).
2. Custom metrics `naver-sms/comparison/sms_sent_old`, `naver-sms/comparison/sms_sent_new`, `naver-sms/comparison/match_percentage`, and `naver-sms/comparison/discrepancies` are published per invocation with dimensions that let dashboards display both functions side by side (`docs/epics/epic-5-deployment.md:140-143`, `docs/epics/epic-5-deployment.md:282-306`).
3. Monitoring captures character-by-character SMS payload comparisons and parity checks for DynamoDB and Telegram interactions, surfacing mismatches with identifiers so engineers can trace affected bookings immediately (`docs/prd.md:526-533`, `docs/brownfield-architecture.md:1683-1710`).

**Integration Requirements**
4. CloudWatch dashboard displays comparison metrics next to Lambda health statistics with widgets aligned to the operations runbook layout (`docs/epics/epic-5-deployment.md:225-229`, `docs/ops/runbook.md:5-39`).
5. Alerts for discrepancies >0, match percentage <100%, and Lambda error rate >5% trigger Slack, Telegram, and email notifications specified in the monitoring plan, with alarm state changes recorded for validation evidence (`docs/epics/epic-5-deployment.md:145-148`, `docs/epics/epic-5-deployment.md:284-304`, `docs/epics/epic-5-deployment.md:231-273`).
6. Comparison telemetry integrates with CloudWatch Logs Insights queries by exposing fields/labels referenced in the operations queries catalog, enabling investigations without new tooling (`docs/ops/cloudwatch-queries.md:15-112`, `docs/ops/cloudwatch-queries.md:312-388`).

**Quality Requirements**
7. Monitoring data retains at least the 7-day validation history needed to prove 100% match and zero discrepancies at the Day 7 go/no-go gate (`docs/epics/epic-5-deployment.md:231-269`).
8. Updated operations runbook sections describe how to interpret comparison dashboard widgets and respond to new alarms introduced by this story (`docs/ops/runbook.md:42-153`, `docs/epics/epic-5-deployment.md:225-229`).
9. Evidence of alarm simulations, dashboard screenshots, and sample log queries is appended to `VALIDATION.md` to satisfy the epic’s audit trail requirements (`docs/epics/epic-5-deployment.md:231-273`).
10. Runtime configuration exposes a documented kill switch (e.g., `Settings` flag or environment variable) that defaults comparison runs to non-sending mode and can disable telemetry quickly without redeploying (`src/config/settings.py:1`, `docs/prd.md:434-438`).

---

## Tasks / Subtasks

- [ ] Implement comparison telemetry pipeline for both Lambdas, emitting structured logs and metrics per invocation (AC 1, AC 2, AC 3).
  - [ ] Define and document the log schema/fields referenced by CloudWatch Logs Insights so operations queries continue to work (AC 1, AC 6).
- [ ] Introduce a manual approval gate (e.g., feature flag in `src/config/settings.py` or deployment parameter) that keeps SMS delivery disabled until the owner authorizes live SENS communication, and document the activation procedure (AC 5, AC 10).
- [ ] Update Terraform (module + environment) to provision comparison metric filters, dashboards, IAM permissions, and alarm subscriptions; record `terraform plan` output for validation (AC 2, AC 4, AC 5, AC 7).
  - [ ] Ensure both Lambda roles include `cloudwatch:PutMetricData` and SNS publish access for alarm topics before deployment (`docs/epics/epic-5-deployment.md:212-217`, `infrastructure/terraform/modules/cloudwatch/main.tf:1`).
- [ ] Build or update the CloudWatch dashboard and alarms that visualize the comparison metrics and enforce thresholds (`naver-sms/comparison/*`, Lambda errors, match percentage) (AC 2, AC 4, AC 5).
  - [ ] Validate Slack/Telegram/email notifications by executing alarm state transitions and archiving the outputs for QA (AC 5, AC 9).
- [ ] Refresh operational documentation: extend `docs/ops/runbook.md` and append new comparison queries to `docs/ops/cloudwatch-queries.md`, cross-linking dashboard widgets to response steps (AC 4, AC 6, AC 8).
  - [ ] Ensure the operations team can trace discrepancies from alarm → dashboard → log search without additional tooling (AC 6, AC 8).
- [ ] Collect validation artifacts (metric screenshots, alarm state transitions, log query transcripts) and store them in `VALIDATION.md` for the Go/No-Go review (AC 5, AC 7, AC 9).
  - [ ] Highlight how the stored metrics demonstrate 7-day retention and zero discrepancies to support the Day 7 decision (AC 7, AC 9).

---

## Dev Notes

- Leverage the structured logger and masking patterns already defined for production so comparison logs remain compatible with existing monitoring queries (`docs/ops/logging.md:418-437`, `docs/ops/cloudwatch-queries.md:15-112`).
- Publish CloudWatch metrics using the exact namespaces and thresholds described in the monitoring plan to avoid rework during go/no-go reviews (`docs/epics/epic-5-deployment.md:140-148`, `docs/epics/epic-5-deployment.md:282-304`).
- Maintain zero-downtime guarantees by ensuring monitoring rollout does not modify the legacy trigger behavior and still supports rapid rollback paths (`docs/prd.md:434-438`, `docs/epics/epic-5-deployment.md:152-168`).
- Record all CLI outputs, dashboards, and alarm tests in `VALIDATION.md` so Story 5.5 can rely on the evidence without rerunning setup steps (`docs/epics/epic-5-deployment.md:231-269`, `docs/epics/epic-5-deployment.md:260-265`).
- Document the manual approval workflow for promoting from simulated comparison runs to live SENS interactions; the default deployment must keep SMS delivery disabled until explicit owner sign-off.
- Mirror all infrastructure changes in Terraform so the CloudWatch module remains the single source of truth; avoid ad-hoc alarm creation in the console (`infrastructure/terraform/modules/cloudwatch/main.tf:1`, `infrastructure/terraform/main.tf:1`).

### Testing

- Run automated comparison tests (replaying captured bookings) to confirm mismatch detection and metric population behaves as expected (`docs/brownfield-architecture.md:1683-1710`).
- Use `aws cloudwatch get-metric-statistics` or equivalent to verify `naver-sms/comparison/*` metrics publish values for both Lambdas after test invocations (`docs/epics/epic-5-deployment.md:140-143`, `docs/epics/epic-5-deployment.md:282-304`).
- Simulate alarm thresholds (e.g., `aws cloudwatch set-alarm-state`) to ensure Slack/Telegram/email integrations fire and captures are ready for validation (`docs/epics/epic-5-deployment.md:145-148`, `docs/epics/epic-5-deployment.md:284-304`).
- Execute the documented Logs Insights queries to confirm structured comparison fields support investigations without query changes (`docs/ops/cloudwatch-queries.md:15-112`, `docs/ops/cloudwatch-queries.md:312-388`).
- Validate that the SENS approval flag blocks outbound SMS during comparison runs by running tests in both disabled and enabled states, and record the evidence before granting live access.
- Include a smoke-test recipe in `docs/ops/runbook.md` that runs one invocation, checks `aws cloudwatch list-metrics --namespace naver-sms/comparison`, and verifies dashboards update within the monitored window (AC 4, AC 8).

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 0.1 | Initial story drafted from Epic 5 comparison monitoring requirements | Sarah (PO) |

---

## Dev Agent Record

### Agent Model Used
- Pending assignment

### Debug Log References
- Pending implementation

### Completion Notes
- No development activity recorded yet; update upon implementation.

### File List
- Pending updates

---

## QA Results

### Review Date
- Pending review

### Reviewed By
- Pending assignment

### Summary
- QA evaluation not yet performed; populate after readiness review.

name: comparison-tests

on:
  push:
    branches:
      - main
      - Epic2
    paths:
      - "src/**"
      - "tests/comparison/**"
      - "tests/fixtures/production_*.json"
      - ".github/workflows/comparison-tests.yml"
      - "pytest.ini"
      - "Makefile"
  pull_request:
    paths:
      - "src/**"
      - "tests/comparison/**"
      - "tests/fixtures/production_*.json"
      - ".github/workflows/comparison-tests.yml"
  workflow_dispatch:
    inputs:
      verbose:
        description: "Enable verbose output"
        required: false
        default: "false"

jobs:
  comparison-parity:
    name: Output Parity Validation
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Load fixtures
        run: |
          echo "üìÅ Verifying comparison fixtures..."
          ls -lh tests/fixtures/production_*.json
          python -c "
          import json
          with open('tests/fixtures/production_bookings.json') as f:
              bookings = json.load(f)
              print(f'‚úÖ Loaded {len(bookings[\"bookings\"])} bookings')
          with open('tests/fixtures/production_expected_outputs.json') as f:
              expected = json.load(f)
              print(f'‚úÖ Loaded {len(expected[\"expected_outputs\"])} expected outputs')
          "

      - name: Run comparison parity tests
        run: |
          pytest tests/comparison/test_output_parity.py::TestOutputParity::test_all_scenarios_parity \
            -v --tb=short \
            --junit-xml=comparison-results.xml || true

      - name: Run fixture validation tests
        run: |
          pytest tests/comparison/test_output_parity.py::TestComparisonFixtures \
            -v --tb=short

      - name: Run masking enforcement tests
        run: |
          pytest tests/comparison/test_output_parity.py::TestOutputParity::test_masking_enforcement \
            -v --tb=short

      - name: Run determinism validation
        run: |
          pytest tests/comparison/test_output_parity.py::TestOutputParity::test_determinism \
            -v --tb=short || true

      - name: Generate coverage report
        run: |
          pytest tests/comparison/ \
            --cov=src --cov=tests/comparison \
            --cov-report=term-missing --cov-report=json \
            --cov-fail-under=80 || true

      - name: Create parity summary report
        if: always()
        run: |
          python << 'EOF'
          import json
          import glob
          from datetime import datetime

          # Collect all JSON results
          results = []
          for json_file in glob.glob("tests/comparison/results/*.json"):
            try:
              with open(json_file) as f:
                results.append(json.load(f))
            except:
              pass

          # Generate summary
          summary = {
            "timestamp": datetime.now().isoformat(),
            "total_tests": len(results),
            "passed": sum(1 for r in results if r.get("parity_status") == "PASS"),
            "failed": sum(1 for r in results if r.get("parity_status") == "FAIL"),
          }

          with open("tests/comparison/results/PARITY_SUMMARY.json", "w") as f:
            json.dump(summary, f, indent=2)

          print(f"‚úÖ Parity Report: {summary['passed']}/{summary['total_tests']} passed")
          EOF

      - name: Upload comparison artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: comparison-results
          path: |
            tests/comparison/results/
            comparison-results.xml
            coverage.json
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('tests/comparison/results/SUMMARY.md')) {
              const summary = fs.readFileSync('tests/comparison/results/SUMMARY.md', 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: '## üìä Comparison Testing Results\n\n' + summary
              });
            }

      - name: Fail if critical mismatches found
        run: |
          if [ -f tests/comparison/results/SUMMARY.md ]; then
            # Extract the number of failed tests from the SUMMARY.md
            FAILED_COUNT=$(grep "Failed:" tests/comparison/results/SUMMARY.md | grep -o "[0-9]\+" | head -1)

            if [ -n "$FAILED_COUNT" ] && [ "$FAILED_COUNT" -gt 0 ]; then
              echo "‚ùå Parity validation failed with $FAILED_COUNT critical mismatches"
              exit 1
            else
              echo "‚úÖ All parity tests passed (0 failures)"
            fi
          else
            echo "‚ö†Ô∏è SUMMARY.md not found, skipping parity validation check"
          fi

  security-check:
    name: Fixture Security Check
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for PII in fixtures
        run: |
          echo "üîí Checking for raw PII in fixtures..."
          
          # Pattern: Korean phone numbers (01X-XXXX-XXXX)
          if grep -r "01[0-9]-[0-9]\{3,4\}-[0-9]\{4\}" tests/fixtures/production_*.json; then
            echo "‚ùå Found raw phone numbers in fixtures!"
            exit 1
          fi
          
          # Pattern: Raw Korean names (Í∞Ä-Ìû£ characters in sequences)
          if grep -r "[Í∞Ä-Ìû£]\{2,\}" tests/fixtures/production_*.json | grep -v "option"; then
            echo "‚ö†Ô∏è Found Korean text patterns - verify no PII"
          fi
          
          echo "‚úÖ Fixture security check passed"

  coverage:
    name: Coverage Report
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Generate coverage
        run: |
          pytest tests/comparison/ \
            --cov=src/rules --cov=tests/comparison \
            --cov-report=html --cov-report=term-missing || true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: comparison
          name: comparison-coverage
          fail_ci_if_error: false
